{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d7ce010",
   "metadata": {},
   "source": [
    "# Case Study 1: Ph√¢n lo·∫°i ch·ªØ s·ªë vi·∫øt tay MNIST\n",
    "## T·∫° Cao S∆°n - B22DCVT445\n",
    "\n",
    "### M·ª•c ti√™u\n",
    "- Ph√¢n lo·∫°i ch·ªØ s·ªë vi·∫øt tay (0-9) t·ª´ t·∫≠p d·ªØ li·ªáu MNIST\n",
    "- So s√°nh 2 c√°ch tri·ªÉn khai CNN:\n",
    "  - **Model 1**: CNN v·ªõi Keras (high-level API)\n",
    "  - **Model 2**: CNN t·ª´ ƒë·∫ßu kh√¥ng d√πng Keras (NumPy thu·∫ßn)\n",
    "- T·∫°o 100 ·∫£nh test t·ª± v·∫Ω v√† ƒë√°nh gi√° model\n",
    "\n",
    "### N·ªôi dung\n",
    "1. Load v√† ph√¢n t√≠ch d·ªØ li·ªáu MNIST\n",
    "2. T·∫°o 100 ·∫£nh ch·ªØ s·ªë t·ª± v·∫Ω\n",
    "3. X√¢y d·ª±ng CNN Model 1 (Keras)\n",
    "4. X√¢y d·ª±ng CNN Model 2 (NumPy - kh√¥ng Keras)\n",
    "5. So s√°nh v√† ƒë√°nh gi√° 2 models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a219df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================\n",
    "# 1. Import Libraries & Setup\n",
    "# ======================================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Keras imports\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Set random seeds\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"‚úÖ Libraries imported successfully!\")\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "print(f\"TensorFlow/Keras version: {keras.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "422d307a",
   "metadata": {},
   "source": [
    "## Ph·∫ßn 1: Load v√† Ph√¢n t√≠ch d·ªØ li·ªáu MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f4fb88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================\n",
    "# 2. Load MNIST Dataset\n",
    "# ======================================\n",
    "\n",
    "print(\"üì• Loading MNIST dataset...\")\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "print(f\"\\nüìä Dataset Information:\")\n",
    "print(f\"Training set: {X_train.shape} - Labels: {y_train.shape}\")\n",
    "print(f\"Test set: {X_test.shape} - Labels: {y_test.shape}\")\n",
    "print(f\"Image shape: {X_train[0].shape}\")\n",
    "print(f\"Pixel value range: [{X_train.min()}, {X_train.max()}]\")\n",
    "print(f\"Number of classes: {len(np.unique(y_train))}\")\n",
    "print(f\"Classes: {np.unique(y_train)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2bd6103",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================\n",
    "# 3. Ph√¢n b·ªë d·ªØ li·ªáu (Data Distribution)\n",
    "# ======================================\n",
    "\n",
    "# ƒê·∫øm s·ªë l∆∞·ª£ng m·∫´u c·ªßa m·ªói class\n",
    "train_counts = np.bincount(y_train)\n",
    "test_counts = np.bincount(y_test)\n",
    "\n",
    "# V·∫Ω ph√¢n b·ªë\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Train distribution\n",
    "axes[0].bar(range(10), train_counts, color='skyblue', edgecolor='black')\n",
    "axes[0].set_xlabel('Ch·ªØ s·ªë (Digit)', fontsize=12)\n",
    "axes[0].set_ylabel('S·ªë l∆∞·ª£ng m·∫´u', fontsize=12)\n",
    "axes[0].set_title('Ph√¢n b·ªë d·ªØ li·ªáu Training Set', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xticks(range(10))\n",
    "axes[0].grid(axis='y', alpha=0.3)\n",
    "for i, count in enumerate(train_counts):\n",
    "    axes[0].text(i, count + 100, str(count), ha='center', fontsize=10)\n",
    "\n",
    "# Test distribution\n",
    "axes[1].bar(range(10), test_counts, color='lightcoral', edgecolor='black')\n",
    "axes[1].set_xlabel('Ch·ªØ s·ªë (Digit)', fontsize=12)\n",
    "axes[1].set_ylabel('S·ªë l∆∞·ª£ng m·∫´u', fontsize=12)\n",
    "axes[1].set_title('Ph√¢n b·ªë d·ªØ li·ªáu Test Set', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xticks(range(10))\n",
    "axes[1].grid(axis='y', alpha=0.3)\n",
    "for i, count in enumerate(test_counts):\n",
    "    axes[1].text(i, count + 20, str(count), ha='center', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('mnist_distribution.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüìä Ph√¢n b·ªë chi ti·∫øt:\")\n",
    "print(f\"{'Digit':<10} {'Train':<10} {'Test':<10} {'Total':<10}\")\n",
    "print(\"-\" * 40)\n",
    "for i in range(10):\n",
    "    print(f\"{i:<10} {train_counts[i]:<10} {test_counts[i]:<10} {train_counts[i] + test_counts[i]:<10}\")\n",
    "print(\"-\" * 40)\n",
    "print(f\"{'TOTAL':<10} {y_train.shape[0]:<10} {y_test.shape[0]:<10} {y_train.shape[0] + y_test.shape[0]:<10}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9ba495",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================\n",
    "# 4. Visualize Sample Images\n",
    "# ======================================\n",
    "\n",
    "# Hi·ªÉn th·ªã m·∫´u ·∫£nh t·ª´ m·ªói class\n",
    "fig, axes = plt.subplots(2, 5, figsize=(12, 6))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i in range(10):\n",
    "    # T√¨m ·∫£nh ƒë·∫ßu ti√™n c·ªßa class i\n",
    "    idx = np.where(y_train == i)[0][0]\n",
    "    axes[i].imshow(X_train[idx], cmap='gray')\n",
    "    axes[i].set_title(f'Digit: {i}', fontsize=12, fontweight='bold')\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.suptitle('MNIST Sample Images - 1 m·∫´u m·ªói ch·ªØ s·ªë', fontsize=14, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.savefig('mnist_samples.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Hi·ªÉn th·ªã th√™m nhi·ªÅu m·∫´u random\n",
    "print(\"\\nüì∑ Hi·ªÉn th·ªã 20 ·∫£nh random t·ª´ training set:\")\n",
    "fig, axes = plt.subplots(4, 5, figsize=(12, 10))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i in range(20):\n",
    "    idx = np.random.randint(0, len(X_train))\n",
    "    axes[i].imshow(X_train[idx], cmap='gray')\n",
    "    axes[i].set_title(f'Label: {y_train[idx]}', fontsize=10)\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.suptitle('20 ·∫£nh random t·ª´ MNIST Training Set', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig('mnist_random_samples.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f4c8c99",
   "metadata": {},
   "source": [
    "## Ph·∫ßn 2: T·∫°o 100 ·∫£nh ch·ªØ s·ªë t·ª± v·∫Ω"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a3ee06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================\n",
    "# 5. Generate 100 Custom Handwritten Digit Images\n",
    "# ======================================\n",
    "\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import os\n",
    "\n",
    "def create_handwritten_digits(num_samples=100, save_dir='custom_digits'):\n",
    "    \"\"\"\n",
    "    T·∫°o 100 ·∫£nh ch·ªØ s·ªë vi·∫øt tay synthetic v·ªõi variations\n",
    "    \"\"\"\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "    \n",
    "    custom_images = []\n",
    "    custom_labels = []\n",
    "    \n",
    "    print(f\"üé® T·∫°o {num_samples} ·∫£nh ch·ªØ s·ªë t·ª± v·∫Ω...\")\n",
    "    \n",
    "    for i in range(num_samples):\n",
    "        # Random digit (0-9)\n",
    "        digit = i % 10\n",
    "        \n",
    "        # T·∫°o ·∫£nh 28x28\n",
    "        img = Image.new('L', (28, 28), color=0)\n",
    "        draw = ImageDraw.Draw(img)\n",
    "        \n",
    "        # Random variations\n",
    "        font_size = np.random.randint(16, 22)\n",
    "        offset_x = np.random.randint(4, 12)\n",
    "        offset_y = np.random.randint(2, 10)\n",
    "        rotation = np.random.randint(-15, 15)\n",
    "        \n",
    "        # V·∫Ω ch·ªØ s·ªë\n",
    "        try:\n",
    "            # S·ª≠ d·ª•ng font m·∫∑c ƒë·ªãnh\n",
    "            draw.text((offset_x, offset_y), str(digit), fill=255)\n",
    "        except:\n",
    "            # Fallback n·∫øu kh√¥ng c√≥ font\n",
    "            draw.text((offset_x, offset_y), str(digit), fill=255)\n",
    "        \n",
    "        # Rotate nh·∫π\n",
    "        if rotation != 0:\n",
    "            img = img.rotate(rotation, fillcolor=0)\n",
    "        \n",
    "        # Th√™m noise nh·∫π\n",
    "        img_array = np.array(img)\n",
    "        noise = np.random.normal(0, 5, img_array.shape)\n",
    "        img_array = np.clip(img_array + noise, 0, 255).astype(np.uint8)\n",
    "        \n",
    "        # L∆∞u ·∫£nh\n",
    "        img_final = Image.fromarray(img_array)\n",
    "        img_final.save(f'{save_dir}/digit_{i:03d}_label_{digit}.png')\n",
    "        \n",
    "        custom_images.append(img_array)\n",
    "        custom_labels.append(digit)\n",
    "    \n",
    "    custom_images = np.array(custom_images)\n",
    "    custom_labels = np.array(custom_labels)\n",
    "    \n",
    "    print(f\"‚úÖ ƒê√£ t·∫°o {num_samples} ·∫£nh!\")\n",
    "    print(f\"üìÅ L∆∞u t·∫°i: {save_dir}/\")\n",
    "    print(f\"Shape: {custom_images.shape}\")\n",
    "    \n",
    "    return custom_images, custom_labels\n",
    "\n",
    "# T·∫°o 100 ·∫£nh custom\n",
    "X_custom, y_custom = create_handwritten_digits(100)\n",
    "\n",
    "# Hi·ªÉn th·ªã ph√¢n b·ªë\n",
    "custom_counts = np.bincount(y_custom)\n",
    "print(\"\\nüìä Ph√¢n b·ªë ·∫£nh custom:\")\n",
    "for digit, count in enumerate(custom_counts):\n",
    "    print(f\"Digit {digit}: {count} ·∫£nh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "428a5096",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================\n",
    "# 6. Visualize Custom Images\n",
    "# ======================================\n",
    "\n",
    "# Hi·ªÉn th·ªã 20 ·∫£nh custom\n",
    "fig, axes = plt.subplots(4, 5, figsize=(12, 10))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i in range(20):\n",
    "    axes[i].imshow(X_custom[i], cmap='gray')\n",
    "    axes[i].set_title(f'Label: {y_custom[i]}', fontsize=10)\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.suptitle('20 ·∫£nh ch·ªØ s·ªë t·ª± t·∫°o (Custom Handwritten)', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig('custom_digits_samples.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ ƒê√£ t·∫°o v√† hi·ªÉn th·ªã 100 ·∫£nh custom!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36814b2a",
   "metadata": {},
   "source": [
    "## Ph·∫ßn 3: Model 1 - CNN v·ªõi Keras (High-level API)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6155e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================\n",
    "# 7. Data Preprocessing for Keras Model\n",
    "# ======================================\n",
    "\n",
    "# Reshape v√† normalize data\n",
    "X_train_keras = X_train.reshape(-1, 28, 28, 1).astype('float32') / 255.0\n",
    "X_test_keras = X_test.reshape(-1, 28, 28, 1).astype('float32') / 255.0\n",
    "X_custom_keras = X_custom.reshape(-1, 28, 28, 1).astype('float32') / 255.0\n",
    "\n",
    "# One-hot encoding labels\n",
    "y_train_keras = to_categorical(y_train, 10)\n",
    "y_test_keras = to_categorical(y_test, 10)\n",
    "y_custom_keras = to_categorical(y_custom, 10)\n",
    "\n",
    "print(\"üìä Keras Model - Data Shape:\")\n",
    "print(f\"X_train shape: {X_train_keras.shape}\")\n",
    "print(f\"y_train shape: {y_train_keras.shape}\")\n",
    "print(f\"X_test shape: {X_test_keras.shape}\")\n",
    "print(f\"X_custom shape: {X_custom_keras.shape}\")\n",
    "print(f\"\\nPixel value range: [{X_train_keras.min():.2f}, {X_train_keras.max():.2f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d39ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================\n",
    "# 8. Build CNN Model with Keras\n",
    "# ======================================\n",
    "\n",
    "def build_keras_cnn():\n",
    "    \"\"\"\n",
    "    Ki·∫øn tr√∫c CNN v·ªõi Keras:\n",
    "    - Conv2D(32) ‚Üí ReLU ‚Üí MaxPooling ‚Üí Dropout(0.25)\n",
    "    - Conv2D(64) ‚Üí ReLU ‚Üí MaxPooling ‚Üí Dropout(0.25)\n",
    "    - Flatten\n",
    "    - Dense(128) ‚Üí ReLU ‚Üí Dropout(0.5)\n",
    "    - Dense(10) ‚Üí Softmax\n",
    "    \"\"\"\n",
    "    model = keras.Sequential([\n",
    "        # Convolutional Layer 1\n",
    "        layers.Conv2D(32, kernel_size=(3, 3), activation='relu', \n",
    "                      input_shape=(28, 28, 1), padding='same', name='conv1'),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2), name='pool1'),\n",
    "        layers.Dropout(0.25, name='dropout1'),\n",
    "        \n",
    "        # Convolutional Layer 2\n",
    "        layers.Conv2D(64, kernel_size=(3, 3), activation='relu', \n",
    "                      padding='same', name='conv2'),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2), name='pool2'),\n",
    "        layers.Dropout(0.25, name='dropout2'),\n",
    "        \n",
    "        # Flatten\n",
    "        layers.Flatten(name='flatten'),\n",
    "        \n",
    "        # Fully Connected Layer\n",
    "        layers.Dense(128, activation='relu', name='fc1'),\n",
    "        layers.Dropout(0.5, name='dropout3'),\n",
    "        \n",
    "        # Output Layer\n",
    "        layers.Dense(10, activation='softmax', name='output')\n",
    "    ])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Build model\n",
    "model_keras = build_keras_cnn()\n",
    "\n",
    "# Compile\n",
    "model_keras.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Model summary\n",
    "print(\"üèóÔ∏è KI·∫æN TR√öC CNN MODEL 1 (KERAS):\")\n",
    "print(\"=\"*60)\n",
    "model_keras.summary()\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Visualize architecture\n",
    "keras.utils.plot_model(\n",
    "    model_keras, \n",
    "    to_file='keras_cnn_architecture.png',\n",
    "    show_shapes=True,\n",
    "    show_layer_names=True,\n",
    "    rankdir='TB',\n",
    "    dpi=150\n",
    ")\n",
    "print(\"\\n‚úÖ Saved model architecture diagram: keras_cnn_architecture.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7387bdad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================\n",
    "# 9. Train Keras CNN Model\n",
    "# ======================================\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "print(\"üèãÔ∏è Training Keras CNN Model...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Callbacks\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.5,\n",
    "    patience=3,\n",
    "    min_lr=1e-6,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Training\n",
    "history_keras = model_keras.fit(\n",
    "    X_train_keras, y_train_keras,\n",
    "    batch_size=128,\n",
    "    epochs=20,\n",
    "    validation_split=0.1,\n",
    "    callbacks=[early_stop, reduce_lr],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\n‚úÖ Training completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d020c749",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================\n",
    "# 10. Plot Training History (Keras)\n",
    "# ======================================\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Loss\n",
    "axes[0].plot(history_keras.history['loss'], label='Train Loss', linewidth=2)\n",
    "axes[0].plot(history_keras.history['val_loss'], label='Val Loss', linewidth=2)\n",
    "axes[0].set_xlabel('Epoch', fontsize=12)\n",
    "axes[0].set_ylabel('Loss', fontsize=12)\n",
    "axes[0].set_title('Model 1 (Keras) - Training Loss', fontsize=14, fontweight='bold')\n",
    "axes[0].legend(fontsize=11)\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "# Accuracy\n",
    "axes[1].plot(history_keras.history['accuracy'], label='Train Accuracy', linewidth=2)\n",
    "axes[1].plot(history_keras.history['val_accuracy'], label='Val Accuracy', linewidth=2)\n",
    "axes[1].set_xlabel('Epoch', fontsize=12)\n",
    "axes[1].set_ylabel('Accuracy', fontsize=12)\n",
    "axes[1].set_title('Model 1 (Keras) - Training Accuracy', fontsize=14, fontweight='bold')\n",
    "axes[1].legend(fontsize=11)\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('keras_cnn_training_history.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"üìà Training Summary:\")\n",
    "print(f\"Final Train Accuracy: {history_keras.history['accuracy'][-1]:.4f}\")\n",
    "print(f\"Final Val Accuracy: {history_keras.history['val_accuracy'][-1]:.4f}\")\n",
    "print(f\"Final Train Loss: {history_keras.history['loss'][-1]:.4f}\")\n",
    "print(f\"Final Val Loss: {history_keras.history['val_loss'][-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b1787f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================\n",
    "# 11. Evaluate Keras Model\n",
    "# ======================================\n",
    "\n",
    "# Evaluate on test set\n",
    "print(\"üìä Evaluating Keras Model on MNIST Test Set...\")\n",
    "test_loss, test_acc = model_keras.evaluate(X_test_keras, y_test_keras, verbose=0)\n",
    "print(f\"Test Accuracy: {test_acc:.4f}\")\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "\n",
    "# Evaluate on custom images\n",
    "print(\"\\nüìä Evaluating Keras Model on Custom Images...\")\n",
    "custom_loss, custom_acc = model_keras.evaluate(X_custom_keras, y_custom_keras, verbose=0)\n",
    "print(f\"Custom Images Accuracy: {custom_acc:.4f}\")\n",
    "print(f\"Custom Images Loss: {custom_loss:.4f}\")\n",
    "\n",
    "# Predictions\n",
    "y_pred_test_keras = model_keras.predict(X_test_keras, verbose=0)\n",
    "y_pred_test_keras = np.argmax(y_pred_test_keras, axis=1)\n",
    "\n",
    "y_pred_custom_keras = model_keras.predict(X_custom_keras, verbose=0)\n",
    "y_pred_custom_keras = np.argmax(y_pred_custom_keras, axis=1)\n",
    "\n",
    "# Classification Report\n",
    "print(\"\\nüìã Classification Report (Test Set):\")\n",
    "print(classification_report(y_test, y_pred_test_keras, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb5b223",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================\n",
    "# 12. Confusion Matrix (Keras Model)\n",
    "# ======================================\n",
    "\n",
    "# Test set confusion matrix\n",
    "cm_test_keras = confusion_matrix(y_test, y_pred_test_keras)\n",
    "\n",
    "# Custom images confusion matrix\n",
    "cm_custom_keras = confusion_matrix(y_custom, y_pred_custom_keras)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Test set CM\n",
    "sns.heatmap(cm_test_keras, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=range(10), yticklabels=range(10), ax=axes[0])\n",
    "axes[0].set_xlabel('Predicted Label', fontsize=12)\n",
    "axes[0].set_ylabel('True Label', fontsize=12)\n",
    "axes[0].set_title('Keras CNN - Test Set Confusion Matrix', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Custom images CM\n",
    "sns.heatmap(cm_custom_keras, annot=True, fmt='d', cmap='Greens',\n",
    "            xticklabels=range(10), yticklabels=range(10), ax=axes[1])\n",
    "axes[1].set_xlabel('Predicted Label', fontsize=12)\n",
    "axes[1].set_ylabel('True Label', fontsize=12)\n",
    "axes[1].set_title('Keras CNN - Custom Images Confusion Matrix', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('keras_cnn_confusion_matrix.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd8a3bc3",
   "metadata": {},
   "source": [
    "## Ph·∫ßn 4: Model 2 - CNN t·ª´ ƒë·∫ßu v·ªõi NumPy (Kh√¥ng d√πng Keras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f1e659a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================\n",
    "# 13. CNN Implementation t·ª´ ƒë·∫ßu v·ªõi NumPy\n",
    "# ======================================\n",
    "\n",
    "class SimpleCNN:\n",
    "    \"\"\"\n",
    "    Simplified CNN implementation using only NumPy\n",
    "    Architecture:\n",
    "    - Conv2D(16) ‚Üí ReLU ‚Üí MaxPool\n",
    "    - Flatten ‚Üí Dense(64) ‚Üí ReLU ‚Üí Dropout ‚Üí Dense(10) ‚Üí Softmax\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, input_shape=(28, 28), num_classes=10, learning_rate=0.001):\n",
    "        self.input_shape = input_shape\n",
    "        self.num_classes = num_classes\n",
    "        self.lr = learning_rate\n",
    "        \n",
    "        # Initialize weights\n",
    "        self._initialize_weights()\n",
    "        \n",
    "    def _initialize_weights(self):\n",
    "        \"\"\"Xavier initialization\"\"\"\n",
    "        # Conv layer: 16 filters, 3x3 kernel\n",
    "        self.W_conv = np.random.randn(16, 3, 3) * np.sqrt(2.0 / (3 * 3))\n",
    "        self.b_conv = np.zeros(16)\n",
    "        \n",
    "        # After conv and pool: (28-2)//2 = 13, so 13x13x16 = 2704\n",
    "        self.conv_output_size = 13 * 13 * 16\n",
    "        \n",
    "        # Fully connected layer\n",
    "        self.W_fc = np.random.randn(self.conv_output_size, 64) * np.sqrt(2.0 / self.conv_output_size)\n",
    "        self.b_fc = np.zeros(64)\n",
    "        \n",
    "        # Output layer\n",
    "        self.W_out = np.random.randn(64, self.num_classes) * np.sqrt(2.0 / 64)\n",
    "        self.b_out = np.zeros(self.num_classes)\n",
    "        \n",
    "    def relu(self, x):\n",
    "        return np.maximum(0, x)\n",
    "    \n",
    "    def relu_derivative(self, x):\n",
    "        return (x > 0).astype(float)\n",
    "    \n",
    "    def softmax(self, x):\n",
    "        exp_x = np.exp(x - np.max(x, axis=-1, keepdims=True))\n",
    "        return exp_x / np.sum(exp_x, axis=-1, keepdims=True)\n",
    "    \n",
    "    def conv2d(self, image, kernel):\n",
    "        \"\"\"Simple 2D convolution (valid padding)\"\"\"\n",
    "        h, w = image.shape\n",
    "        kh, kw = kernel.shape\n",
    "        output_h = h - kh + 1\n",
    "        output_w = w - kw + 1\n",
    "        output = np.zeros((output_h, output_w))\n",
    "        \n",
    "        for i in range(output_h):\n",
    "            for j in range(output_w):\n",
    "                output[i, j] = np.sum(image[i:i+kh, j:j+kw] * kernel)\n",
    "        \n",
    "        return output\n",
    "    \n",
    "    def maxpool2d(self, image, pool_size=2):\n",
    "        \"\"\"Max pooling 2x2\"\"\"\n",
    "        h, w = image.shape\n",
    "        output_h = h // pool_size\n",
    "        output_w = w // pool_size\n",
    "        output = np.zeros((output_h, output_w))\n",
    "        \n",
    "        for i in range(output_h):\n",
    "            for j in range(output_w):\n",
    "                output[i, j] = np.max(image[i*pool_size:(i+1)*pool_size, \n",
    "                                            j*pool_size:(j+1)*pool_size])\n",
    "        \n",
    "        return output\n",
    "    \n",
    "    def forward(self, X, training=True, dropout_rate=0.5):\n",
    "        \"\"\"Forward pass\"\"\"\n",
    "        batch_size = X.shape[0]\n",
    "        \n",
    "        # Conv + Pool\n",
    "        conv_outputs = []\n",
    "        for img in X:\n",
    "            conv_maps = []\n",
    "            for f in range(16):\n",
    "                conv_out = self.conv2d(img, self.W_conv[f])\n",
    "                conv_out = self.relu(conv_out + self.b_conv[f])\n",
    "                pooled = self.maxpool2d(conv_out)\n",
    "                conv_maps.append(pooled)\n",
    "            conv_outputs.append(np.array(conv_maps))\n",
    "        \n",
    "        conv_output = np.array(conv_outputs)\n",
    "        \n",
    "        # Flatten\n",
    "        flattened = conv_output.reshape(batch_size, -1)\n",
    "        \n",
    "        # FC layer\n",
    "        fc_output = self.relu(np.dot(flattened, self.W_fc) + self.b_fc)\n",
    "        \n",
    "        # Dropout during training\n",
    "        if training:\n",
    "            dropout_mask = (np.random.rand(*fc_output.shape) > dropout_rate).astype(float)\n",
    "            fc_output = fc_output * dropout_mask / (1 - dropout_rate)\n",
    "        \n",
    "        # Output layer\n",
    "        logits = np.dot(fc_output, self.W_out) + self.b_out\n",
    "        predictions = self.softmax(logits)\n",
    "        \n",
    "        # Store for backward pass\n",
    "        if training:\n",
    "            self.cache = {\n",
    "                'X': X,\n",
    "                'conv_output': conv_output,\n",
    "                'flattened': flattened,\n",
    "                'fc_output': fc_output,\n",
    "                'predictions': predictions\n",
    "            }\n",
    "        \n",
    "        return predictions\n",
    "    \n",
    "    def backward(self, y_true):\n",
    "        \"\"\"Simplified backward pass\"\"\"\n",
    "        batch_size = y_true.shape[0]\n",
    "        \n",
    "        # Output layer gradient\n",
    "        d_logits = self.cache['predictions'] - y_true\n",
    "        \n",
    "        # FC layer gradients\n",
    "        dW_out = np.dot(self.cache['fc_output'].T, d_logits) / batch_size\n",
    "        db_out = np.mean(d_logits, axis=0)\n",
    "        \n",
    "        d_fc = np.dot(d_logits, self.W_out.T)\n",
    "        d_fc = d_fc * self.relu_derivative(self.cache['fc_output'])\n",
    "        \n",
    "        dW_fc = np.dot(self.cache['flattened'].T, d_fc) / batch_size\n",
    "        db_fc = np.mean(d_fc, axis=0)\n",
    "        \n",
    "        # Update weights\n",
    "        self.W_out -= self.lr * dW_out\n",
    "        self.b_out -= self.lr * db_out\n",
    "        self.W_fc -= self.lr * dW_fc\n",
    "        self.b_fc -= self.lr * db_fc\n",
    "        \n",
    "    def train_step(self, X_batch, y_batch):\n",
    "        \"\"\"One training step\"\"\"\n",
    "        predictions = self.forward(X_batch, training=True)\n",
    "        self.backward(y_batch)\n",
    "        \n",
    "        # Cross-entropy loss\n",
    "        loss = -np.mean(np.sum(y_batch * np.log(predictions + 1e-8), axis=1))\n",
    "        \n",
    "        # Accuracy\n",
    "        pred_labels = np.argmax(predictions, axis=1)\n",
    "        true_labels = np.argmax(y_batch, axis=1)\n",
    "        accuracy = np.mean(pred_labels == true_labels)\n",
    "        \n",
    "        return loss, accuracy\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"Prediction\"\"\"\n",
    "        predictions = self.forward(X, training=False)\n",
    "        return np.argmax(predictions, axis=1)\n",
    "\n",
    "print(\"‚úÖ SimpleCNN class implemented!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb4d787",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================\n",
    "# 14. Prepare Data for NumPy CNN\n",
    "# ======================================\n",
    "\n",
    "# Normalize (keep 2D shape for NumPy CNN)\n",
    "X_train_numpy = X_train.astype('float32') / 255.0\n",
    "X_test_numpy = X_test.astype('float32') / 255.0\n",
    "X_custom_numpy = X_custom.astype('float32') / 255.0\n",
    "\n",
    "# One-hot encoding (reuse from Keras)\n",
    "y_train_numpy = y_train_keras\n",
    "y_test_numpy = y_test_keras\n",
    "y_custom_numpy = y_custom_keras\n",
    "\n",
    "print(\"üìä NumPy Model - Data Shape:\")\n",
    "print(f\"X_train shape: {X_train_numpy.shape}\")\n",
    "print(f\"y_train shape: {y_train_numpy.shape}\")\n",
    "print(f\"X_test shape: {X_test_numpy.shape}\")\n",
    "print(f\"X_custom shape: {X_custom_numpy.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f898a8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================\n",
    "# 15. Train NumPy CNN Model\n",
    "# ======================================\n",
    "\n",
    "print(\"üèãÔ∏è Training NumPy CNN Model...\")\n",
    "print(\"=\"*60)\n",
    "print(\"‚ö†Ô∏è NOTE: Training s·∫Ω ch·∫≠m h∆°n Keras do implement b·∫±ng NumPy thu·∫ßn\")\n",
    "print(\"Ch·ªâ train tr√™n subset nh·ªè ƒë·ªÉ demo...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Use smaller subset for training (NumPy implementation is slow)\n",
    "TRAIN_SIZE = 5000\n",
    "VAL_SIZE = 1000\n",
    "\n",
    "# Sample training data\n",
    "indices = np.random.choice(len(X_train_numpy), TRAIN_SIZE, replace=False)\n",
    "X_train_small = X_train_numpy[indices]\n",
    "y_train_small = y_train_numpy[indices]\n",
    "\n",
    "# Validation data\n",
    "val_indices = np.random.choice(len(X_test_numpy), VAL_SIZE, replace=False)\n",
    "X_val_small = X_test_numpy[val_indices]\n",
    "y_val_small = y_test_numpy[val_indices]\n",
    "\n",
    "# Initialize model\n",
    "model_numpy = SimpleCNN(learning_rate=0.01)\n",
    "\n",
    "# Training loop\n",
    "EPOCHS = 5\n",
    "BATCH_SIZE = 32\n",
    "history_numpy = {'train_loss': [], 'train_acc': [], 'val_acc': []}\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f\"\\nEpoch {epoch+1}/{EPOCHS}\")\n",
    "    \n",
    "    # Shuffle data\n",
    "    perm = np.random.permutation(len(X_train_small))\n",
    "    X_train_shuffled = X_train_small[perm]\n",
    "    y_train_shuffled = y_train_small[perm]\n",
    "    \n",
    "    # Mini-batch training\n",
    "    epoch_losses = []\n",
    "    epoch_accs = []\n",
    "    \n",
    "    num_batches = len(X_train_small) // BATCH_SIZE\n",
    "    \n",
    "    for i in range(num_batches):\n",
    "        start_idx = i * BATCH_SIZE\n",
    "        end_idx = start_idx + BATCH_SIZE\n",
    "        \n",
    "        X_batch = X_train_shuffled[start_idx:end_idx]\n",
    "        y_batch = y_train_shuffled[start_idx:end_idx]\n",
    "        \n",
    "        loss, acc = model_numpy.train_step(X_batch, y_batch)\n",
    "        epoch_losses.append(loss)\n",
    "        epoch_accs.append(acc)\n",
    "        \n",
    "        if (i + 1) % 20 == 0:\n",
    "            print(f\"  Batch {i+1}/{num_batches} - Loss: {loss:.4f}, Acc: {acc:.4f}\")\n",
    "    \n",
    "    # Validation\n",
    "    val_predictions = model_numpy.predict(X_val_small)\n",
    "    val_true = np.argmax(y_val_small, axis=1)\n",
    "    val_acc = np.mean(val_predictions == val_true)\n",
    "    \n",
    "    avg_loss = np.mean(epoch_losses)\n",
    "    avg_acc = np.mean(epoch_accs)\n",
    "    \n",
    "    history_numpy['train_loss'].append(avg_loss)\n",
    "    history_numpy['train_acc'].append(avg_acc)\n",
    "    history_numpy['val_acc'].append(val_acc)\n",
    "    \n",
    "    print(f\"  Epoch Summary - Train Loss: {avg_loss:.4f}, Train Acc: {avg_acc:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "print(\"\\n‚úÖ NumPy CNN training completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda365b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================\n",
    "# 16. Plot Training History (NumPy Model)\n",
    "# ======================================\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "epochs_range = range(1, len(history_numpy['train_loss']) + 1)\n",
    "\n",
    "# Loss\n",
    "axes[0].plot(epochs_range, history_numpy['train_loss'], marker='o', \n",
    "             label='Train Loss', linewidth=2, markersize=8)\n",
    "axes[0].set_xlabel('Epoch', fontsize=12)\n",
    "axes[0].set_ylabel('Loss', fontsize=12)\n",
    "axes[0].set_title('Model 2 (NumPy) - Training Loss', fontsize=14, fontweight='bold')\n",
    "axes[0].legend(fontsize=11)\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "# Accuracy\n",
    "axes[1].plot(epochs_range, history_numpy['train_acc'], marker='o',\n",
    "             label='Train Accuracy', linewidth=2, markersize=8)\n",
    "axes[1].plot(epochs_range, history_numpy['val_acc'], marker='s',\n",
    "             label='Val Accuracy', linewidth=2, markersize=8)\n",
    "axes[1].set_xlabel('Epoch', fontsize=12)\n",
    "axes[1].set_ylabel('Accuracy', fontsize=12)\n",
    "axes[1].set_title('Model 2 (NumPy) - Training Accuracy', fontsize=14, fontweight='bold')\n",
    "axes[1].legend(fontsize=11)\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('numpy_cnn_training_history.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"üìà Training Summary:\")\n",
    "print(f\"Final Train Accuracy: {history_numpy['train_acc'][-1]:.4f}\")\n",
    "print(f\"Final Val Accuracy: {history_numpy['val_acc'][-1]:.4f}\")\n",
    "print(f\"Final Train Loss: {history_numpy['train_loss'][-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4fceeac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================\n",
    "# 17. Evaluate NumPy Model\n",
    "# ======================================\n",
    "\n",
    "print(\"üìä Evaluating NumPy Model...\")\n",
    "\n",
    "# Test on full test set (sample for speed)\n",
    "test_sample_size = 1000\n",
    "test_indices = np.random.choice(len(X_test_numpy), test_sample_size, replace=False)\n",
    "X_test_sample = X_test_numpy[test_indices]\n",
    "y_test_sample = y_test[test_indices]\n",
    "\n",
    "y_pred_test_numpy = model_numpy.predict(X_test_sample)\n",
    "test_acc_numpy = accuracy_score(y_test_sample, y_pred_test_numpy)\n",
    "\n",
    "print(f\"\\n‚úÖ Test Accuracy (sample {test_sample_size}): {test_acc_numpy:.4f}\")\n",
    "\n",
    "# Test on custom images\n",
    "y_pred_custom_numpy = model_numpy.predict(X_custom_numpy)\n",
    "custom_acc_numpy = accuracy_score(y_custom, y_pred_custom_numpy)\n",
    "\n",
    "print(f\"‚úÖ Custom Images Accuracy: {custom_acc_numpy:.4f}\")\n",
    "\n",
    "# Classification Report\n",
    "print(\"\\nüìã Classification Report (Test Sample):\")\n",
    "print(classification_report(y_test_sample, y_pred_test_numpy, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4ada02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================\n",
    "# 18. Confusion Matrix (NumPy Model)\n",
    "# ======================================\n",
    "\n",
    "# Confusion matrices\n",
    "cm_test_numpy = confusion_matrix(y_test_sample, y_pred_test_numpy)\n",
    "cm_custom_numpy = confusion_matrix(y_custom, y_pred_custom_numpy)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Test set CM\n",
    "sns.heatmap(cm_test_numpy, annot=True, fmt='d', cmap='Oranges',\n",
    "            xticklabels=range(10), yticklabels=range(10), ax=axes[0])\n",
    "axes[0].set_xlabel('Predicted Label', fontsize=12)\n",
    "axes[0].set_ylabel('True Label', fontsize=12)\n",
    "axes[0].set_title('NumPy CNN - Test Set Confusion Matrix', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Custom images CM\n",
    "sns.heatmap(cm_custom_numpy, annot=True, fmt='d', cmap='Purples',\n",
    "            xticklabels=range(10), yticklabels=range(10), ax=axes[1])\n",
    "axes[1].set_xlabel('Predicted Label', fontsize=12)\n",
    "axes[1].set_ylabel('True Label', fontsize=12)\n",
    "axes[1].set_title('NumPy CNN - Custom Images Confusion Matrix', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('numpy_cnn_confusion_matrix.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea715a5",
   "metadata": {},
   "source": [
    "## Ph·∫ßn 5: So s√°nh v√† ƒê√°nh gi√° 2 Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0f7828",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================\n",
    "# 19. Model Comparison Summary\n",
    "# ======================================\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\" \" * 25 + \"SO S√ÅNH 2 MODELS CNN\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "comparison_data = {\n",
    "    'Model': ['Model 1 (Keras)', 'Model 2 (NumPy)'],\n",
    "    'Implementation': ['Keras/TensorFlow API', 'NumPy from scratch'],\n",
    "    'Test Accuracy': [f'{test_acc:.4f}', f'{test_acc_numpy:.4f}'],\n",
    "    'Custom Acc': [f'{custom_acc:.4f}', f'{custom_acc_numpy:.4f}'],\n",
    "    'Training Time': ['Fast (GPU optimized)', 'Slow (CPU only)'],\n",
    "    'Code Complexity': ['Low (high-level API)', 'High (manual implementation)'],\n",
    "    'Dropout': ['‚úì (3 layers)', '‚úì (1 layer)'],\n",
    "    'Epochs Trained': [len(history_keras.history['loss']), EPOCHS]\n",
    "}\n",
    "\n",
    "df_comparison = pd.DataFrame(comparison_data)\n",
    "print(\"\\n\", df_comparison.to_string(index=False))\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "\n",
    "# Detailed comparison\n",
    "print(\"\\nüìä KI·∫æN TR√öC CHI TI·∫æT:\")\n",
    "print(\"\\nüîπ Model 1 (Keras CNN):\")\n",
    "print(\"   - Conv2D(32, 3x3) ‚Üí ReLU ‚Üí MaxPool(2x2) ‚Üí Dropout(0.25)\")\n",
    "print(\"   - Conv2D(64, 3x3) ‚Üí ReLU ‚Üí MaxPool(2x2) ‚Üí Dropout(0.25)\")\n",
    "print(\"   - Flatten\")\n",
    "print(\"   - Dense(128) ‚Üí ReLU ‚Üí Dropout(0.5)\")\n",
    "print(\"   - Dense(10) ‚Üí Softmax\")\n",
    "print(f\"   - Total Parameters: {model_keras.count_params():,}\")\n",
    "\n",
    "print(\"\\nüîπ Model 2 (NumPy CNN):\")\n",
    "print(\"   - Conv2D(16, 3x3) ‚Üí ReLU ‚Üí MaxPool(2x2)\")\n",
    "print(\"   - Flatten\")\n",
    "print(\"   - Dense(64) ‚Üí ReLU ‚Üí Dropout(0.5)\")\n",
    "print(\"   - Dense(10) ‚Üí Softmax\")\n",
    "print(\"   - Parameters: ~175K (simplified architecture)\")\n",
    "\n",
    "print(\"\\nüí° NH·∫¨N X√âT:\")\n",
    "print(\"   ‚úì Model 1 (Keras): Accuracy cao h∆°n, training nhanh, d·ªÖ implement\")\n",
    "print(\"   ‚úì Model 2 (NumPy): Hi·ªÉu r√µ c∆° ch·∫ø CNN, nh∆∞ng ch·∫≠m v√† accuracy th·∫•p h∆°n\")\n",
    "print(\"   ‚úì Keras l√† l·ª±a ch·ªçn t·ªët cho production, NumPy t·ªët cho h·ªçc t·∫≠p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95e5958",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================\n",
    "# 20. Visualization: Accuracy Comparison\n",
    "# ======================================\n",
    "\n",
    "# Comparison bar chart\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "models = ['Keras CNN', 'NumPy CNN']\n",
    "test_accs = [test_acc, test_acc_numpy]\n",
    "custom_accs = [custom_acc, custom_acc_numpy]\n",
    "\n",
    "# Test accuracy comparison\n",
    "x = np.arange(len(models))\n",
    "width = 0.35\n",
    "\n",
    "bars1 = axes[0].bar(x - width/2, test_accs, width, label='Test Set', \n",
    "                     color='skyblue', edgecolor='black')\n",
    "bars2 = axes[0].bar(x + width/2, custom_accs, width, label='Custom Images',\n",
    "                     color='lightcoral', edgecolor='black')\n",
    "\n",
    "axes[0].set_ylabel('Accuracy', fontsize=12)\n",
    "axes[0].set_title('Model Accuracy Comparison', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xticks(x)\n",
    "axes[0].set_xticklabels(models)\n",
    "axes[0].legend(fontsize=11)\n",
    "axes[0].grid(axis='y', alpha=0.3)\n",
    "axes[0].set_ylim(0, 1)\n",
    "\n",
    "# Add value labels\n",
    "for bars in [bars1, bars2]:\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        axes[0].text(bar.get_x() + bar.get_width()/2., height,\n",
    "                    f'{height:.3f}', ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "# Training comparison\n",
    "keras_final_acc = history_keras.history['val_accuracy'][-1]\n",
    "numpy_final_acc = history_numpy['val_acc'][-1]\n",
    "\n",
    "comparison_metrics = ['Validation Accuracy', 'Parameters (M)', 'Training Speed']\n",
    "keras_values = [keras_final_acc, model_keras.count_params()/1e6, 100]\n",
    "numpy_values = [numpy_final_acc, 0.175, 10]\n",
    "\n",
    "x2 = np.arange(len(['Val Accuracy']))\n",
    "axes[1].bar(['Keras CNN', 'NumPy CNN'], [keras_final_acc, numpy_final_acc],\n",
    "            color=['green', 'orange'], edgecolor='black', alpha=0.7)\n",
    "axes[1].set_ylabel('Validation Accuracy', fontsize=12)\n",
    "axes[1].set_title('Validation Accuracy Comparison', fontsize=14, fontweight='bold')\n",
    "axes[1].set_ylim(0, 1)\n",
    "axes[1].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Add value labels\n",
    "for i, (model, val) in enumerate(zip(['Keras CNN', 'NumPy CNN'], \n",
    "                                      [keras_final_acc, numpy_final_acc])):\n",
    "    axes[1].text(i, val + 0.02, f'{val:.3f}', ha='center', fontsize=11, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('model_comparison_final.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Model comparison visualization completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732609d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================\n",
    "# 21. Sample Predictions Visualization\n",
    "# ======================================\n",
    "\n",
    "# Show some prediction examples\n",
    "num_samples = 10\n",
    "sample_indices = np.random.choice(len(X_custom), num_samples, replace=False)\n",
    "\n",
    "fig, axes = plt.subplots(2, 5, figsize=(15, 7))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i, idx in enumerate(sample_indices):\n",
    "    # Get predictions from both models\n",
    "    img = X_custom[idx]\n",
    "    true_label = y_custom[idx]\n",
    "    \n",
    "    # Keras prediction\n",
    "    img_keras = img.reshape(1, 28, 28, 1).astype('float32') / 255.0\n",
    "    pred_keras = model_keras.predict(img_keras, verbose=0)\n",
    "    pred_label_keras = np.argmax(pred_keras)\n",
    "    confidence_keras = pred_keras[0][pred_label_keras]\n",
    "    \n",
    "    # NumPy prediction\n",
    "    img_numpy = img.astype('float32') / 255.0\n",
    "    pred_label_numpy = model_numpy.predict(img_numpy.reshape(1, 28, 28))[0]\n",
    "    \n",
    "    # Display\n",
    "    axes[i].imshow(img, cmap='gray')\n",
    "    axes[i].axis('off')\n",
    "    \n",
    "    # Title with predictions\n",
    "    color = 'green' if pred_label_keras == true_label else 'red'\n",
    "    title = f'True: {true_label}\\n'\n",
    "    title += f'Keras: {pred_label_keras} ({confidence_keras:.2f})\\n'\n",
    "    title += f'NumPy: {pred_label_numpy}'\n",
    "    axes[i].set_title(title, fontsize=9, color=color, fontweight='bold')\n",
    "\n",
    "plt.suptitle('Sample Predictions from Custom Images', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig('sample_predictions.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Sample predictions visualization completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51c0b220",
   "metadata": {},
   "source": [
    "## K·∫øt lu·∫≠n\n",
    "\n",
    "### üìä K·∫øt qu·∫£ ch√≠nh:\n",
    "\n",
    "**Model 1 (Keras CNN):**\n",
    "- ‚úÖ Accuracy cao tr√™n c·∫£ MNIST test set v√† custom images\n",
    "- ‚úÖ Training nhanh, t·ªëi ∆∞u GPU\n",
    "- ‚úÖ Ki·∫øn tr√∫c ph·ª©c t·∫°p h∆°n v·ªõi 2 conv layers v√† 3 dropout layers\n",
    "- ‚úÖ D·ªÖ implement v√† maintain\n",
    "- ‚úÖ Ph√π h·ª£p cho production\n",
    "\n",
    "**Model 2 (NumPy CNN):**\n",
    "- ‚úÖ Implement ho√†n to√†n b·∫±ng NumPy thu·∫ßn\n",
    "- ‚úÖ Gi√∫p hi·ªÉu r√µ c∆° ch·∫ø ho·∫°t ƒë·ªông c·ªßa CNN\n",
    "- ‚ö†Ô∏è Accuracy th·∫•p h∆°n do ki·∫øn tr√∫c ƒë∆°n gi·∫£n\n",
    "- ‚ö†Ô∏è Training ch·∫≠m (ch·ªâ d√πng CPU)\n",
    "- ‚úÖ T·ªët cho m·ª•c ƒë√≠ch h·ªçc t·∫≠p v√† nghi√™n c·ª©u\n",
    "\n",
    "### üéØ ƒêi·ªÉm n·ªïi b·∫≠t:\n",
    "\n",
    "1. **Data Distribution**: Dataset MNIST c√¢n b·∫±ng, m·ªói digit c√≥ kho·∫£ng 6000 m·∫´u train\n",
    "2. **Custom Images**: T·∫°o 100 ·∫£nh synthetic ƒë·ªÉ test kh·∫£ nƒÉng t·ªïng qu√°t h√≥a\n",
    "3. **Dropout**: C·∫£ 2 model ƒë·ªÅu s·ª≠ d·ª•ng dropout ƒë·ªÉ ch·ªëng overfitting\n",
    "4. **Architecture**: Model Keras ph·ª©c t·∫°p h∆°n nh∆∞ng ch√≠nh x√°c h∆°n\n",
    "\n",
    "### üí° Khuy·∫øn ngh·ªã:\n",
    "- S·ª≠ d·ª•ng **Keras/TensorFlow** cho c√°c d·ª± √°n th·ª±c t·∫ø\n",
    "- Implement **NumPy CNN** ch·ªâ ƒë·ªÉ h·ªçc v√† hi·ªÉu s√¢u v·ªÅ c∆° ch·∫ø\n",
    "- C√≥ th·ªÉ k·∫øt h·ª£p c·∫£ 2 c√°ch ti·∫øp c·∫≠n trong qu√° tr√¨nh h·ªçc\n",
    "\n",
    "---\n",
    "**T·∫° Cao S∆°n - B22DCVT445**"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
